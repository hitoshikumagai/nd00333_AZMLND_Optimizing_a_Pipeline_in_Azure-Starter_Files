{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gather": {
     "logged": 1598275788035
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace name: udacitydemoml2\n",
      "Azure region: eastus2\n",
      "Subscription id: 9d855d0b-cba0-4253-aa5d-91f6e6ebc1d5\n",
      "Resource group: udacitycvdemo\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace, Experiment, Dataset\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "exp = Experiment(workspace=ws, name=\"udacity-project\")\n",
    "\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')\n",
    "\n",
    "run = exp.start_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SK-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup Cluster for sklearn training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1598275788675
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n",
      "{'currentNodeCount': 0, 'targetNodeCount': 0, 'nodeStateCounts': {'preparingNodeCount': 0, 'runningNodeCount': 0, 'idleNodeCount': 0, 'unusableNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0}, 'allocationState': 'Steady', 'allocationStateTransitionTime': '2024-09-28T09:52:25.057000+00:00', 'errors': None, 'creationTime': '2024-09-28T04:00:44.715513+00:00', 'modifiedTime': '2024-09-28T04:00:54.729448+00:00', 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 0, 'maxNodeCount': 1, 'nodeIdleTimeBeforeScaleDown': 'PT120S'}, 'vmPriority': 'Dedicated', 'vmSize': 'Standard_D2_v2'}\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "\n",
    "cluster_name = \"ml-project-nd00333\"\n",
    "\n",
    "# TODO: Create compute cluster\n",
    "# Use vm_size = \"Standard_D2_V2\" in your provisioning configuration.\n",
    "# max_nodes should be no greater than 4.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing compute target')\n",
    "except ComputeTargetException:\n",
    "    print('Creating a new compute target...')\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='Standard_D2_V2', \n",
    "                                                           max_nodes=4)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "# can poll for a minimum number of nodes and for a specific timeout. \n",
    "# if no min node count is provided it uses the scale settings for the cluster\n",
    "compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "\n",
    "# use get_status() to get a detailed status for the current cluster. \n",
    "print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Hyper parameter tuning for sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1598275789986
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "from azureml.train.sklearn import SKLearn\n",
    "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
    "from azureml.train.hyperdrive.policy import BanditPolicy\n",
    "from azureml.train.hyperdrive.sampling import RandomParameterSampling\n",
    "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
    "from azureml.train.hyperdrive.parameter_expressions import choice, uniform\n",
    "from azureml.core import Environment, ScriptRunConfig\n",
    "import os\n",
    "\n",
    "# Specify parameter sampler\n",
    "### YOUR CODE HERE ###\n",
    "ps = RandomParameterSampling(\n",
    "    {\n",
    "        '--max_iter': choice(50, 100, 200),\n",
    "        '--C': uniform(0.01, 10)\n",
    "    }\n",
    ")\n",
    "\n",
    "# Specify a Policy\n",
    "### YOUR CODE HERE ###\n",
    "policy = BanditPolicy(evaluation_interval=2, slack_factor=0.1)\n",
    "\n",
    "if \"training\" not in os.listdir():\n",
    "    os.mkdir(\"./training\")\n",
    "    \n",
    "# Setup environment for your training run\n",
    "sklearn_env = Environment.from_conda_specification(name='sklearn-env', file_path='conda_dependencies.yml')\n",
    "\n",
    "# Create a ScriptRunConfig Object to specify the configuration details of your training job\n",
    "### YOUR CODE HERE ###\n",
    "src = ScriptRunConfig(source_directory='.', \n",
    "                      script='train.py', \n",
    "                      compute_target=compute_target,\n",
    "                      environment=sklearn_env)\n",
    "\n",
    "# Create a HyperDriveConfig using the src object, hyperparameter sampler, and policy.\n",
    "### YOUR CODE HERE ###\n",
    "hyperdrive_config = HyperDriveConfig(run_config=src,\n",
    "                                     hyperparameter_sampling=ps,\n",
    "                                     policy=policy,\n",
    "                                     primary_metric_name='Accuracy',\n",
    "                                     primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
    "                                     max_total_runs=20,\n",
    "                                     max_concurrent_runs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Submit your hyperdrive run to the experiment and show run details with the widget.\n",
    "run = exp.submit(hyperdrive_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: HD_ec98bade-a6c5-4a06-a4f1-31b5aaac2e66\n",
      "Web View: https://ml.azure.com/runs/HD_ec98bade-a6c5-4a06-a4f1-31b5aaac2e66?wsid=/subscriptions/9d855d0b-cba0-4253-aa5d-91f6e6ebc1d5/resourcegroups/udacitycvdemo/workspaces/udacitydemoml2&tid=c50d08fb-64e9-430f-b8fd-e1eae4d0b61c\n",
      "\n",
      "Streaming azureml-logs/hyperdrive.txt\n",
      "=====================================\n",
      "\n",
      "[2024-09-28T10:09:43.407323][GENERATOR][INFO]Trying to sample '4' jobs from the hyperparameter space\n",
      "[2024-09-28T10:09:43.8522516Z][SCHEDULER][INFO]Scheduling job, id='HD_ec98bade-a6c5-4a06-a4f1-31b5aaac2e66_0' \n",
      "[2024-09-28T10:09:43.9898554Z][SCHEDULER][INFO]Scheduling job, id='HD_ec98bade-a6c5-4a06-a4f1-31b5aaac2e66_1' \n",
      "[2024-09-28T10:09:44.1774160Z][SCHEDULER][INFO]Scheduling job, id='HD_ec98bade-a6c5-4a06-a4f1-31b5aaac2e66_3' \n",
      "[2024-09-28T10:09:44.1024656Z][SCHEDULER][INFO]Scheduling job, id='HD_ec98bade-a6c5-4a06-a4f1-31b5aaac2e66_2' \n",
      "[2024-09-28T10:09:44.137179][GENERATOR][INFO]Successfully sampled '4' jobs, they will soon be submitted to the execution target.\n",
      "[2024-09-28T10:09:45.6639736Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_ec98bade-a6c5-4a06-a4f1-31b5aaac2e66_0' \n",
      "[2024-09-28T10:09:45.8733457Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_ec98bade-a6c5-4a06-a4f1-31b5aaac2e66_1' \n",
      "[2024-09-28T10:09:45.9271553Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_ec98bade-a6c5-4a06-a4f1-31b5aaac2e66_3' \n",
      "[2024-09-28T10:09:46.0628309Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_ec98bade-a6c5-4a06-a4f1-31b5aaac2e66_2' \n",
      "[2024-09-28T10:16:13.141394][GENERATOR][INFO]Trying to sample '1' jobs from the hyperparameter space\n",
      "[2024-09-28T10:16:13.370546][GENERATOR][INFO]Successfully sampled '1' jobs, they will soon be submitted to the execution target.\n",
      "[2024-09-28T10:16:13.4576302Z][SCHEDULER][INFO]Scheduling job, id='HD_ec98bade-a6c5-4a06-a4f1-31b5aaac2e66_4' \n",
      "[2024-09-28T10:16:13.7013966Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_ec98bade-a6c5-4a06-a4f1-31b5aaac2e66_4' \n",
      "[2024-09-28T10:16:43.147045][GENERATOR][INFO]Trying to sample '1' jobs from the hyperparameter space\n",
      "[2024-09-28T10:16:43.4125755Z][SCHEDULER][INFO]Scheduling job, id='HD_ec98bade-a6c5-4a06-a4f1-31b5aaac2e66_5' \n",
      "[2024-09-28T10:16:43.366128][GENERATOR][INFO]Successfully sampled '1' jobs, they will soon be submitted to the execution target.\n",
      "[2024-09-28T10:16:43.6405014Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_ec98bade-a6c5-4a06-a4f1-31b5aaac2e66_5' \n",
      "[2024-09-28T10:17:13.149461][GENERATOR][INFO]Trying to sample '1' jobs from the hyperparameter space\n",
      "[2024-09-28T10:17:13.5049577Z][SCHEDULER][INFO]Scheduling job, id='HD_ec98bade-a6c5-4a06-a4f1-31b5aaac2e66_6' \n",
      "[2024-09-28T10:17:13.449580][GENERATOR][INFO]Successfully sampled '1' jobs, they will soon be submitted to the execution target.\n",
      "[2024-09-28T10:17:13.7283312Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_ec98bade-a6c5-4a06-a4f1-31b5aaac2e66_6' \n",
      "[2024-09-28T10:17:43.169510][GENERATOR][INFO]Trying to sample '1' jobs from the hyperparameter space\n",
      "[2024-09-28T10:17:43.5634040Z][SCHEDULER][INFO]Scheduling job, id='HD_ec98bade-a6c5-4a06-a4f1-31b5aaac2e66_7' \n",
      "[2024-09-28T10:17:43.496431][GENERATOR][INFO]Successfully sampled '1' jobs, they will soon be submitted to the execution target.\n",
      "[2024-09-28T10:17:43.8332147Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_ec98bade-a6c5-4a06-a4f1-31b5aaac2e66_7' \n",
      "[2024-09-28T10:18:43.150611][GENERATOR][INFO]Trying to sample '1' jobs from the hyperparameter space\n",
      "[2024-09-28T10:18:43.4460900Z][SCHEDULER][INFO]Scheduling job, id='HD_ec98bade-a6c5-4a06-a4f1-31b5aaac2e66_8' \n",
      "[2024-09-28T10:18:43.389083][GENERATOR][INFO]Successfully sampled '1' jobs, they will soon be submitted to the execution target.\n",
      "[2024-09-28T10:18:43.6916203Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_ec98bade-a6c5-4a06-a4f1-31b5aaac2e66_8' \n",
      "[2024-09-28T10:19:13.149447][GENERATOR][INFO]Trying to sample '1' jobs from the hyperparameter space\n",
      "[2024-09-28T10:19:13.4852712Z][SCHEDULER][INFO]Scheduling job, id='HD_ec98bade-a6c5-4a06-a4f1-31b5aaac2e66_9' \n",
      "[2024-09-28T10:19:13.440885][GENERATOR][INFO]Successfully sampled '1' jobs, they will soon be submitted to the execution target.\n",
      "[2024-09-28T10:19:13.7396656Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_ec98bade-a6c5-4a06-a4f1-31b5aaac2e66_9' \n",
      "[2024-09-28T10:19:43.147003][GENERATOR][INFO]Trying to sample '1' jobs from the hyperparameter space\n",
      "[2024-09-28T10:19:43.4977170Z][SCHEDULER][INFO]Scheduling job, id='HD_ec98bade-a6c5-4a06-a4f1-31b5aaac2e66_10' \n",
      "[2024-09-28T10:19:43.439404][GENERATOR][INFO]Successfully sampled '1' jobs, they will soon be submitted to the execution target.\n",
      "[2024-09-28T10:19:43.7533498Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_ec98bade-a6c5-4a06-a4f1-31b5aaac2e66_10' \n",
      "[2024-09-28T10:20:43.148382][GENERATOR][INFO]Trying to sample '1' jobs from the hyperparameter space\n",
      "[2024-09-28T10:20:43.4884290Z][SCHEDULER][INFO]Scheduling job, id='HD_ec98bade-a6c5-4a06-a4f1-31b5aaac2e66_11' \n",
      "[2024-09-28T10:20:43.442353][GENERATOR][INFO]Successfully sampled '1' jobs, they will soon be submitted to the execution target.\n",
      "[2024-09-28T10:20:43.7605103Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_ec98bade-a6c5-4a06-a4f1-31b5aaac2e66_11' \n",
      "[2024-09-28T10:21:13.163671][GENERATOR][INFO]Trying to sample '1' jobs from the hyperparameter space\n",
      "[2024-09-28T10:21:13.4808162Z][SCHEDULER][INFO]Scheduling job, id='HD_ec98bade-a6c5-4a06-a4f1-31b5aaac2e66_12' \n",
      "[2024-09-28T10:21:13.446340][GENERATOR][INFO]Successfully sampled '1' jobs, they will soon be submitted to the execution target.\n",
      "[2024-09-28T10:21:15.2186700Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_ec98bade-a6c5-4a06-a4f1-31b5aaac2e66_12' \n",
      "[2024-09-28T10:21:43.174442][GENERATOR][INFO]Trying to sample '1' jobs from the hyperparameter space\n",
      "[2024-09-28T10:21:43.4341592Z][SCHEDULER][INFO]Scheduling job, id='HD_ec98bade-a6c5-4a06-a4f1-31b5aaac2e66_13' \n",
      "[2024-09-28T10:21:43.388842][GENERATOR][INFO]Successfully sampled '1' jobs, they will soon be submitted to the execution target.\n",
      "[2024-09-28T10:21:43.6705867Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_ec98bade-a6c5-4a06-a4f1-31b5aaac2e66_13' \n",
      "[2024-09-28T10:22:43.200198][GENERATOR][INFO]Trying to sample '1' jobs from the hyperparameter space\n",
      "[2024-09-28T10:22:43.4774318Z][SCHEDULER][INFO]Scheduling job, id='HD_ec98bade-a6c5-4a06-a4f1-31b5aaac2e66_14' \n",
      "[2024-09-28T10:22:43.435022][GENERATOR][INFO]Successfully sampled '1' jobs, they will soon be submitted to the execution target.\n",
      "[2024-09-28T10:22:43.7426470Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_ec98bade-a6c5-4a06-a4f1-31b5aaac2e66_14' \n",
      "[2024-09-28T10:23:13.134601][GENERATOR][INFO]Trying to sample '1' jobs from the hyperparameter space\n",
      "[2024-09-28T10:23:13.5485075Z][SCHEDULER][INFO]Scheduling job, id='HD_ec98bade-a6c5-4a06-a4f1-31b5aaac2e66_15' \n",
      "[2024-09-28T10:23:13.432924][GENERATOR][INFO]Successfully sampled '1' jobs, they will soon be submitted to the execution target.\n",
      "[2024-09-28T10:23:13.7954193Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_ec98bade-a6c5-4a06-a4f1-31b5aaac2e66_15' \n",
      "[2024-09-28T10:23:43.225697][GENERATOR][INFO]Trying to sample '1' jobs from the hyperparameter space\n",
      "[2024-09-28T10:23:43.528114][GENERATOR][INFO]Successfully sampled '1' jobs, they will soon be submitted to the execution target.\n",
      "[2024-09-28T10:23:43.6623711Z][SCHEDULER][INFO]Scheduling job, id='HD_ec98bade-a6c5-4a06-a4f1-31b5aaac2e66_16' \n",
      "[2024-09-28T10:23:43.9571717Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_ec98bade-a6c5-4a06-a4f1-31b5aaac2e66_16' \n",
      "[2024-09-28T10:24:43.211304][GENERATOR][INFO]Trying to sample '1' jobs from the hyperparameter space\n",
      "[2024-09-28T10:24:43.5553820Z][SCHEDULER][INFO]Scheduling job, id='HD_ec98bade-a6c5-4a06-a4f1-31b5aaac2e66_17' \n",
      "[2024-09-28T10:24:43.507445][GENERATOR][INFO]Successfully sampled '1' jobs, they will soon be submitted to the execution target.\n",
      "[2024-09-28T10:24:43.8008197Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_ec98bade-a6c5-4a06-a4f1-31b5aaac2e66_17' \n",
      "[2024-09-28T10:25:13.165694][GENERATOR][INFO]Trying to sample '1' jobs from the hyperparameter space\n",
      "[2024-09-28T10:25:13.472723][GENERATOR][INFO]Successfully sampled '1' jobs, they will soon be submitted to the execution target.\n",
      "[2024-09-28T10:25:13.5604559Z][SCHEDULER][INFO]Scheduling job, id='HD_ec98bade-a6c5-4a06-a4f1-31b5aaac2e66_18' \n",
      "[2024-09-28T10:25:13.8068789Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_ec98bade-a6c5-4a06-a4f1-31b5aaac2e66_18' \n",
      "[2024-09-28T10:25:43.189632][GENERATOR][INFO]Trying to sample '1' jobs from the hyperparameter space\n",
      "[2024-09-28T10:25:43.5777392Z][SCHEDULER][INFO]Scheduling job, id='HD_ec98bade-a6c5-4a06-a4f1-31b5aaac2e66_19' \n",
      "[2024-09-28T10:25:43.511890][GENERATOR][INFO]Successfully sampled '1' jobs, they will soon be submitted to the execution target.\n",
      "[2024-09-28T10:25:43.8386633Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_ec98bade-a6c5-4a06-a4f1-31b5aaac2e66_19' \n",
      "[2024-09-28T10:26:13.307200][GENERATOR][INFO]Max number of jobs '20' reached for experiment.\n",
      "[2024-09-28T10:26:13.476429][GENERATOR][INFO]All jobs generated.\n",
      "[2024-09-28T10:28:22.2443024Z][CONTROLLER][INFO]Changing Run Status from Running to Completed \n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: HD_ec98bade-a6c5-4a06-a4f1-31b5aaac2e66\n",
      "Web View: https://ml.azure.com/runs/HD_ec98bade-a6c5-4a06-a4f1-31b5aaac2e66?wsid=/subscriptions/9d855d0b-cba0-4253-aa5d-91f6e6ebc1d5/resourcegroups/udacitycvdemo/workspaces/udacitydemoml2&tid=c50d08fb-64e9-430f-b8fd-e1eae4d0b61c\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'HD_ec98bade-a6c5-4a06-a4f1-31b5aaac2e66',\n",
       " 'target': 'ml-project-nd00333',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2024-09-28T10:09:42.545647Z',\n",
       " 'endTimeUtc': '2024-09-28T10:28:22.422717Z',\n",
       " 'services': {},\n",
       " 'properties': {'primary_metric_config': '{\"name\":\"Accuracy\",\"goal\":\"maximize\"}',\n",
       "  'resume_from': 'null',\n",
       "  'runTemplate': 'HyperDrive',\n",
       "  'azureml.runsource': 'hyperdrive',\n",
       "  'platform': 'AML',\n",
       "  'ContentSnapshotId': 'a6bba97a-cbef-4182-9244-81ea5f04e5e7',\n",
       "  'user_agent': 'python/3.9.19 (Linux-5.15.0-1064-azure-x86_64-with-glibc2.31) msrest/0.7.1 Hyperdrive.Service/1.0.0 Hyperdrive.SDK/core.1.56.0',\n",
       "  'space_size': 'infinite_space_size',\n",
       "  'best_child_run_id': 'HD_ec98bade-a6c5-4a06-a4f1-31b5aaac2e66_10',\n",
       "  'score': '0.9088012139605464',\n",
       "  'best_metric_status': 'Succeeded',\n",
       "  'best_data_container_id': 'dcid.HD_ec98bade-a6c5-4a06-a4f1-31b5aaac2e66_10'},\n",
       " 'inputDatasets': [],\n",
       " 'outputDatasets': [],\n",
       " 'runDefinition': {'configuration': None,\n",
       "  'attribution': None,\n",
       "  'telemetryValues': {'amlClientType': 'azureml-sdk-train',\n",
       "   'amlClientModule': '[Scrubbed]',\n",
       "   'amlClientFunction': '[Scrubbed]',\n",
       "   'tenantId': 'c50d08fb-64e9-430f-b8fd-e1eae4d0b61c',\n",
       "   'amlClientRequestId': '09271324-04d6-49d2-b292-b13277ceb1f6',\n",
       "   'amlClientSessionId': 'f1f37786-9ee8-4664-8c0e-844397c91003',\n",
       "   'subscriptionId': '9d855d0b-cba0-4253-aa5d-91f6e6ebc1d5',\n",
       "   'estimator': 'NoneType',\n",
       "   'samplingMethod': 'RANDOM',\n",
       "   'terminationPolicy': 'Bandit',\n",
       "   'primaryMetricGoal': 'maximize',\n",
       "   'maxTotalRuns': 20,\n",
       "   'maxConcurrentRuns': 4,\n",
       "   'maxDurationMinutes': 10080,\n",
       "   'vmSize': None},\n",
       "  'snapshotId': 'a6bba97a-cbef-4182-9244-81ea5f04e5e7',\n",
       "  'snapshots': [],\n",
       "  'sourceCodeDataReference': None,\n",
       "  'parentRunId': None,\n",
       "  'dataContainerId': None,\n",
       "  'runType': None,\n",
       "  'displayName': None,\n",
       "  'environmentAssetId': None,\n",
       "  'properties': {},\n",
       "  'tags': {},\n",
       "  'aggregatedArtifactPath': None},\n",
       " 'logFiles': {'azureml-logs/hyperdrive.txt': 'https://udacitydemoml24884002156.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_ec98bade-a6c5-4a06-a4f1-31b5aaac2e66/azureml-logs/hyperdrive.txt?sv=2019-07-07&sr=b&sig=kWG5OYtihFs4mQS%2FaBLnXVaYxX65gPo6cW805K34X%2B0%3D&skoid=69e024fe-4651-41eb-b6cd-632c109b7c16&sktid=c50d08fb-64e9-430f-b8fd-e1eae4d0b61c&skt=2024-09-28T04%3A48%3A30Z&ske=2024-09-30T04%3A58%3A30Z&sks=b&skv=2019-07-07&st=2024-09-28T10%3A18%3A39Z&se=2024-09-28T18%3A28%3A39Z&sp=r'},\n",
       " 'submittedBy': 'Hitoshi kumagai'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Regularization Strength:': 6.092621988412589, 'Max iterations:': 100, 'Accuracy': 0.9088012139605463}\n"
     ]
    }
   ],
   "source": [
    "best_run = run.get_best_run_by_primary_metric()\n",
    "hpo_metrics = best_run.get_metrics()\n",
    "print(hpo_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get your best run and save the model from that run.\n",
    "best_model_name = [x for x in best_run.get_file_names() if '.joblib' in x][0]\n",
    "best_run.download_file(name=best_model_name, output_file_path='./training')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.data.dataset_factory import TabularDatasetFactory\n",
    "\n",
    "# Create TabularDataset using TabularDatasetFactory\n",
    "# Data is available at: \n",
    "# \"https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv\"\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "csv_pth = 'https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv'\n",
    "ds = TabularDatasetFactory.from_delimited_files(path=csv_pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1598275726969
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'infer_column_types': 'False', 'activity': 'to_pandas_dataframe'}\n",
      "{'infer_column_types': 'False', 'activity': 'to_pandas_dataframe', 'activityApp': 'TabularDataset'}\n",
      "Validating arguments.\n",
      "Arguments validated.\n",
      "Column header contains '.' This period will be translated to '_' as we write the data out to parquet files: 'emp.var.rate' -> 'emp_var_rate'\n",
      "Column header contains '.' This period will be translated to '_' as we write the data out to parquet files: 'cons.price.idx' -> 'cons_price_idx'\n",
      "Column header contains '.' This period will be translated to '_' as we write the data out to parquet files: 'cons.conf.idx' -> 'cons_conf_idx'\n",
      "Column header contains '.' This period will be translated to '_' as we write the data out to parquet files: 'nr.employed' -> 'nr_employed'\n",
      "Column header contains '.' This period will be translated to '_' as we write the data out to parquet files: 'job_admin.' -> 'job_admin_'\n",
      "Column header contains '.' This period will be translated to '_' as we write the data out to parquet files: 'education_basic.4y' -> 'education_basic_4y'\n",
      "Column header contains '.' This period will be translated to '_' as we write the data out to parquet files: 'education_basic.6y' -> 'education_basic_6y'\n",
      "Column header contains '.' This period will be translated to '_' as we write the data out to parquet files: 'education_basic.9y' -> 'education_basic_9y'\n",
      "Column header contains '.' This period will be translated to '_' as we write the data out to parquet files: 'education_high.school' -> 'education_high_school'\n",
      "Column header contains '.' This period will be translated to '_' as we write the data out to parquet files: 'education_professional.course' -> 'education_professional_course'\n",
      "Column header contains '.' This period will be translated to '_' as we write the data out to parquet files: 'education_university.degree' -> 'education_university_degree'\n",
      "Validating arguments.\n",
      "Arguments validated.\n",
      "'overwrite' is set to True. Any file already present in the target will be overwritten.\n",
      "Uploading files from '/tmp/tmppo_hu8ft' to 'train.csv/5686038f-c988-4132-aa41-ad7a0017f44e/'\n",
      "Copying 1 files with concurrency set to 1\n",
      "Copied /tmp/tmppo_hu8ft/dataframe.parquet, file 1 out of 1. Destination path: https://udacitydemoml24884002156.blob.core.windows.net/azureml-blobstore-9b035900-4732-4319-b840-b602b0e5962a/train.csv/5686038f-c988-4132-aa41-ad7a0017f44e/dataframe.parquet\n",
      "Successfully uploaded file to datastore.\n",
      "Creating and registering a new dataset.\n",
      "Files copied=1, skipped=0, failed=0\n",
      "Successfully created and registered a new dataset.\n"
     ]
    }
   ],
   "source": [
    "from train import clean_data\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Use the clean_data function to clean your data.\n",
    "x, y = clean_data(ds)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "train_df = pd.concat([x_train,y_train], axis=1)\n",
    "\n",
    "train_df.to_csv('train.csv', index=False)\n",
    "\n",
    "# set datastore\n",
    "datastore = ws.get_default_datastore()\n",
    "\n",
    "# register dataset from pandas dataframe\n",
    "dataset = Dataset.Tabular.register_pandas_dataframe(\n",
    "    dataframe=train_df, \n",
    "    target=(datastore, 'train.csv'),  \n",
    "    name='bankmarketing_train_automl' \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and run AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1598275665403
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.train.automl import AutoMLConfig\n",
    "\n",
    "# Set parameters for AutoMLConfig\n",
    "# NOTE: DO NOT CHANGE THE experiment_timeout_minutes PARAMETER OR YOUR INSTANCE WILL TIME OUT.\n",
    "# If you wish to run the experiment longer, you will need to run this notebook in your own\n",
    "# Azure tenant, which will incur personal costs.\n",
    "automl_config = AutoMLConfig(\n",
    "    experiment_timeout_minutes=30,\n",
    "    task='classification',\n",
    "    primary_metric='accuracy',\n",
    "    training_data=dataset,\n",
    "    label_column_name='y',\n",
    "    n_cross_validations=5,\n",
    "    compute_target=compute_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting remote run.\n",
      "No run_configuration provided, running on ml-project-nd00333 with default configuration\n",
      "Running on remote compute: ml-project-nd00333\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>udacity-project</td><td>AutoML_71520427-47ea-41b8-b176-7733096b7c9b</td><td>automl</td><td>NotStarted</td><td><a href=\"https://ml.azure.com/runs/AutoML_71520427-47ea-41b8-b176-7733096b7c9b?wsid=/subscriptions/9d855d0b-cba0-4253-aa5d-91f6e6ebc1d5/resourcegroups/udacitycvdemo/workspaces/udacitydemoml2&amp;tid=c50d08fb-64e9-430f-b8fd-e1eae4d0b61c\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current status: FeaturesGeneration. Generating features for the dataset.\n",
      "Current status: DatasetFeaturization. Beginning to fit featurizers and featurize the dataset.\n",
      "Current status: DatasetBalancing. Performing class balancing sweeping\n",
      "Current status: DatasetCrossValidationSplit. Generating individually featurized CV splits.\n",
      "Current status: ModelSelection. Beginning model selection.\n",
      "\n",
      "********************************************************************************************\n",
      "DATA GUARDRAILS: \n",
      "\n",
      "TYPE:         Class balancing detection\n",
      "STATUS:       ALERTED\n",
      "DESCRIPTION:  To decrease model bias, please cancel the current run and fix balancing problem.\n",
      "              Learn more about imbalanced data: https://aka.ms/AutomatedMLImbalancedData\n",
      "DETAILS:      Imbalanced data can lead to a falsely perceived positive effect of a model's accuracy because the input data has bias towards one class.\n",
      "+------------------------------+--------------------------------+--------------------------------------+\n",
      "|Size of the smallest class    |Name/Label of the smallest class|Number of samples in the training data|\n",
      "+==============================+================================+======================================+\n",
      "|2951                          |1                               |26360                                 |\n",
      "+------------------------------+--------------------------------+--------------------------------------+\n",
      "\n",
      "********************************************************************************************\n",
      "\n",
      "TYPE:         Missing feature values imputation\n",
      "STATUS:       PASSED\n",
      "DESCRIPTION:  No feature missing values were detected in the training data.\n",
      "              Learn more about missing value imputation: https://aka.ms/AutomatedMLFeaturization\n",
      "\n",
      "********************************************************************************************\n",
      "\n",
      "TYPE:         High cardinality feature detection\n",
      "STATUS:       PASSED\n",
      "DESCRIPTION:  Your inputs were analyzed, and no high cardinality features were detected.\n",
      "              Learn more about high cardinality feature handling: https://aka.ms/AutomatedMLFeaturization\n",
      "\n",
      "********************************************************************************************\n",
      "\n",
      "********************************************************************************************\n",
      "ITER: The iteration being evaluated.\n",
      "PIPELINE: A summary description of the pipeline being evaluated.\n",
      "DURATION: Time taken for the current iteration.\n",
      "METRIC: The result of computing score on the fitted pipeline.\n",
      "BEST: The best observed score thus far.\n",
      "********************************************************************************************\n",
      "\n",
      " ITER   PIPELINE                                       DURATION            METRIC      BEST\n",
      "    0   MaxAbsScaler LightGBM                          0:00:12             0.9166    0.9166\n",
      "    1   MaxAbsScaler XGBoostClassifier                 0:00:27             0.9125    0.9166\n",
      "    2   MaxAbsScaler ExtremeRandomTrees                0:00:16             0.7300    0.9166\n",
      "    3   SparseNormalizer XGBoostClassifier             0:00:16             0.9145    0.9166\n",
      "    4   MaxAbsScaler LightGBM                          0:00:10             0.9130    0.9166\n",
      "    5   MaxAbsScaler LightGBM                          0:00:09             0.8881    0.9166\n",
      "    6   StandardScalerWrapper XGBoostClassifier        0:00:12             0.9120    0.9166\n",
      "    7   MaxAbsScaler LogisticRegression                0:00:14             0.9082    0.9166\n",
      "    8   StandardScalerWrapper ExtremeRandomTrees       0:00:10             0.8883    0.9166\n",
      "    9   StandardScalerWrapper XGBoostClassifier        0:00:10             0.9141    0.9166\n",
      "   10   SparseNormalizer LightGBM                      0:00:10             0.9055    0.9166\n",
      "   11   StandardScalerWrapper XGBoostClassifier        0:00:10             0.9139    0.9166\n",
      "   12   MaxAbsScaler LogisticRegression                0:00:12             0.9087    0.9166\n",
      "   13   MaxAbsScaler SGD                               0:00:09             0.8586    0.9166\n",
      "   14   StandardScalerWrapper XGBoostClassifier        0:00:12             0.9131    0.9166\n",
      "   15   SparseNormalizer RandomForest                  0:00:29             0.8120    0.9166\n",
      "   16   StandardScalerWrapper LogisticRegression       0:00:10             0.9093    0.9166\n",
      "   17   StandardScalerWrapper RandomForest             0:00:17             0.9011    0.9166\n",
      "   18   StandardScalerWrapper XGBoostClassifier        0:00:16             0.9137    0.9166\n",
      "   19   TruncatedSVDWrapper RandomForest               0:02:42             0.8209    0.9166\n",
      "   20   TruncatedSVDWrapper RandomForest               0:04:46             0.8313    0.9166\n",
      "   21   StandardScalerWrapper XGBoostClassifier        0:00:37             0.9146    0.9166\n",
      "   22   StandardScalerWrapper LightGBM                 0:00:43             0.9135    0.9166\n",
      "   23   MaxAbsScaler LightGBM                          0:00:34             0.8881    0.9166\n",
      "   24   StandardScalerWrapper XGBoostClassifier        0:01:18             0.9153    0.9166\n",
      "   25   MaxAbsScaler LightGBM                          0:00:35             0.8881    0.9166\n",
      "   26   MaxAbsScaler LightGBM                          0:00:34             0.9107    0.9166\n",
      "   27   SparseNormalizer LightGBM                      0:00:34             0.9028    0.9166\n",
      "   28   StandardScalerWrapper XGBoostClassifier        0:01:57             0.9073    0.9166\n",
      "   29   MaxAbsScaler LightGBM                          0:00:42             0.9110    0.9166\n",
      "   30    VotingEnsemble                                0:01:06             0.9183    0.9183\n",
      "   31    StackEnsemble                                 0:01:16             0.9166    0.9183\n"
     ]
    }
   ],
   "source": [
    "# Submit your automl run\n",
    "\n",
    "automl_run = exp.submit(automl_config, show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model and Metrics for AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./training/bestAutoMl.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve and save your best automl model.\n",
    "import joblib\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "best, model = automl_run.get_output()\n",
    "joblib.dump(model, './training/bestAutoMl.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9183232169954477\n"
     ]
    }
   ],
   "source": [
    "# show metrics\n",
    "metrics = best.get_metrics()\n",
    "print(metrics['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score_macro: 0.799\n",
      "accuracy: 0.918\n",
      "recall_score_micro: 0.918\n",
      "precision_score_micro: 0.918\n",
      "precision_score_weighted: 0.915\n",
      "average_precision_score_weighted: 0.956\n",
      "balanced_accuracy: 0.776\n",
      "log_loss: 0.303\n",
      "weighted_accuracy: 0.954\n",
      "recall_score_macro: 0.776\n",
      "average_precision_score_macro: 0.827\n",
      "f1_score_macro: 0.786\n",
      "AUC_macro: 0.948\n",
      "recall_score_weighted: 0.918\n",
      "matthews_correlation: 0.574\n",
      "f1_score_micro: 0.918\n",
      "AUC_micro: 0.981\n",
      "AUC_weighted: 0.948\n",
      "norm_macro_recall: 0.551\n",
      "average_precision_score_micro: 0.982\n",
      "f1_score_weighted: 0.917\n",
      "confusion_matrix: aml\n",
      "accuracy_table: aml\n"
     ]
    }
   ],
   "source": [
    "for x in metrics.keys():\n",
    "    print(f\"{x}: {metrics[x]:.3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
